{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fa4d9c-4a34-4360-b9db-09994f52a017",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T03:35:06.312198Z",
     "iopub.status.busy": "2025-06-12T03:35:06.311841Z",
     "iopub.status.idle": "2025-06-12T03:35:06.316596Z",
     "shell.execute_reply": "2025-06-12T03:35:06.315849Z",
     "shell.execute_reply.started": "2025-06-12T03:35:06.312166Z"
    }
   },
   "source": [
    "# MODEL TRAINING: SageMaker's Image-Classifier (Transfer Learning) (Time Split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4821b0f-6794-46ef-a1a3-01c040eb0bd8",
   "metadata": {},
   "source": [
    "Required Inputs:\n",
    "* source s3 bucket: images split into train and validation.\n",
    "* .lst files: train and val\n",
    "\n",
    "Output:\n",
    "* output s3 bucket: images from the source bucket are reorganized into a new bucket under subfolder train/ or validation/ according to the split rule\n",
    "* .lst files for each train and validation folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886cc6ed-a57a-45a5-bda7-345b596d95c3",
   "metadata": {},
   "source": [
    "---\n",
    "## Permissions and Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4fa4bdd-cabc-448a-8cb4-c6826f1d7f47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T15:43:37.969742Z",
     "iopub.status.busy": "2025-06-19T15:43:37.969486Z",
     "iopub.status.idle": "2025-06-19T15:43:40.368266Z",
     "shell.execute_reply": "2025-06-19T15:43:40.367279Z",
     "shell.execute_reply.started": "2025-06-19T15:43:37.969719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "arn:aws:iam::324183265896:role/service-role/AmazonSageMaker-ExecutionRole-20250604T045982\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# project bucket\n",
    "bucket_name = \"aai-540-data\"\n",
    "\n",
    "# image source and lst files\n",
    "images_prefix = \"cct_resized\"\n",
    "s3_images_location = f\"s3://{bucket_name}/{images_prefix}/\"\n",
    "s3_train_lst = \"s3://aai-540-data/dev_split/train.lst\"\n",
    "s3_validation_lst = \"s3://aai-540-data/dev_split/validation.lst\"\n",
    "s3_test_lst = \"s3://aai-540-data/dev_split/test.lst\"\n",
    "#val_lst_key = \"\n",
    "\n",
    "# specifiy output location of training data and model\n",
    "output_prefix = \"sg-ic-transfer-learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908bfb5d-1dcf-4540-9f6e-f45c300f232a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T15:43:47.663128Z",
     "iopub.status.busy": "2025-06-19T15:43:47.662322Z",
     "iopub.status.idle": "2025-06-19T15:43:47.692545Z",
     "shell.execute_reply": "2025-06-19T15:43:47.691565Z",
     "shell.execute_reply.started": "2025-06-19T15:43:47.663093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:1\n"
     ]
    }
   ],
   "source": [
    "# retrieve base SageMakers image-classification model \n",
    "from sagemaker import image_uris\n",
    "\n",
    "training_image = image_uris.retrieve(\n",
    "    framework = \"image-classification\", region = sess.boto_region_name, version=\"latest\"\n",
    ")\n",
    "\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c05647aa-eb85-4c48-bb63-0dd1b7d14d29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T15:43:50.770919Z",
     "iopub.status.busy": "2025-06-19T15:43:50.770594Z",
     "iopub.status.idle": "2025-06-19T15:43:50.777114Z",
     "shell.execute_reply": "2025-06-19T15:43:50.776183Z",
     "shell.execute_reply.started": "2025-06-19T15:43:50.770899Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure input channels\n",
    "input_data = {\n",
    "    \"train\": sagemaker.inputs.TrainingInput(\n",
    "        s3_data=s3_images_location,  \n",
    "        content_type=\"application/x-image\",\n",
    "    ),\n",
    "    \"validation\": sagemaker.inputs.TrainingInput(\n",
    "        s3_data=s3_images_location,  # Same directory as training\n",
    "        content_type=\"application/x-image\",\n",
    "    ),\n",
    "    \"train_lst\": sagemaker.inputs.TrainingInput(\n",
    "        #s3_data=s3_images_location + 'train_lst/' + 'train.lst',\n",
    "        s3_data = s3_train_lst,\n",
    "        content_type=\"application/x-image\",\n",
    "    ),\n",
    "    \"validation_lst\": sagemaker.inputs.TrainingInput(\n",
    "        #s3_data=s3_images_location + 'val_lst/' + 'val.lst',\n",
    "        s3_data = s3_validation_lst,\n",
    "        content_type=\"application/x-image\",\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f282570-784e-4af3-9463-b2a671132f7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T15:44:21.470102Z",
     "iopub.status.busy": "2025-06-19T15:44:21.469421Z",
     "iopub.status.idle": "2025-06-19T15:44:21.480072Z",
     "shell.execute_reply": "2025-06-19T15:44:21.479312Z",
     "shell.execute_reply.started": "2025-06-19T15:44:21.470063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure base image classifier\n",
    "s3_output_location = f\"s3://{bucket_name}/{output_prefix}/output\"\n",
    "ic_estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri = training_image,\n",
    "    role = role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    volume_size=50,\n",
    "    max_run=360000,\n",
    "    input_mode=\"File\",\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9d06406-47ba-4c2a-a380-9e9a502b933e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T15:44:52.898408Z",
     "iopub.status.busy": "2025-06-19T15:44:52.898096Z",
     "iopub.status.idle": "2025-06-19T15:44:52.903097Z",
     "shell.execute_reply": "2025-06-19T15:44:52.902365Z",
     "shell.execute_reply.started": "2025-06-19T15:44:52.898385Z"
    }
   },
   "outputs": [],
   "source": [
    "# MAKE SURE THAT NUM_CLASSES are UPDATED ACCORDING TO DECIDED TIME SPLIT\n",
    "# Configure hyper parameters\n",
    "\n",
    "ic_estimator.set_hyperparameters(\n",
    "    num_layers=18, \n",
    "    use_pretrained_model=1,\n",
    "    image_shape=\"3,224,224\",\n",
    "    num_classes=17, # \n",
    "    num_training_samples=28049, # needs to be updated also\n",
    "    mini_batch_size=128,\n",
    "    epochs=10,\n",
    "    learning_rate=0.01,\n",
    "    precision_dtype=\"float32\",\n",
    "    early_stopping=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "631502d5-f594-4df5-ba82-c429362f31f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T15:45:03.746384Z",
     "iopub.status.busy": "2025-06-19T15:45:03.745771Z",
     "iopub.status.idle": "2025-06-19T16:06:05.722521Z",
     "shell.execute_reply": "2025-06-19T16:06:05.721802Z",
     "shell.execute_reply.started": "2025-06-19T15:45:03.746353Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: image-classification-2025-06-19-15-45-03-748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-19 15:45:03 Starting - Starting the training job......\n",
      "2025-06-19 15:46:09 Downloading - Downloading input data............\n",
      "2025-06-19 15:47:55 Downloading - Downloading the training image.........\n",
      "2025-06-19 15:49:16 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34mNvidia gpu devices, drivers and cuda toolkit versions (only available on hosts with GPU):\u001b[0m\n",
      "\u001b[34mThu Jun 19 15:49:28 2025       \u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34m| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |\u001b[0m\n",
      "\u001b[34m|-----------------------------------------+------------------------+----------------------+\u001b[0m\n",
      "\u001b[34m| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\u001b[0m\n",
      "\u001b[34m| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\u001b[0m\n",
      "\u001b[34m|                                         |                        |               MIG M. |\u001b[0m\n",
      "\u001b[34m|=========================================+========================+======================|\u001b[0m\n",
      "\u001b[34m|   0  Tesla T4                       On  |   00000000:00:1E.0 Off |                    0 |\u001b[0m\n",
      "\u001b[34m| N/A   34C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\u001b[0m\n",
      "\u001b[34m|                                         |                        |                  N/A |\u001b[0m\n",
      "\u001b[34m+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34m| Processes:                                                                              |\u001b[0m\n",
      "\u001b[34m|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\u001b[0m\n",
      "\u001b[34m|        ID   ID                                                               Usage      |\u001b[0m\n",
      "\u001b[34m|=========================================================================================|\u001b[0m\n",
      "\u001b[34m|  No running processes found                                                             |\u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34mChecking for nvidia driver and cuda compatibility.\u001b[0m\n",
      "\u001b[34mCUDA Compatibility driver provided.\u001b[0m\n",
      "\u001b[34mProceeding with compatibility check between driver, cuda-toolkit and cuda-compat.\u001b[0m\n",
      "\u001b[34mDetected cuda-toolkit version: 11.1.\u001b[0m\n",
      "\u001b[34mDetected cuda-compat version: 455.32.00.\u001b[0m\n",
      "\u001b[34mDetected Nvidia driver version: 550.163.01.\u001b[0m\n",
      "\u001b[34mNvidia driver compatible with cuda-toolkit. Disabling cuda-compat.\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:31 INFO 139925224236864] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/image_classification/default-input.json: {'use_pretrained_model': 0, 'num_layers': 152, 'epochs': 30, 'learning_rate': 0.1, 'lr_scheduler_factor': 0.1, 'optimizer': 'sgd', 'momentum': 0, 'weight_decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'eps': 1e-08, 'gamma': 0.9, 'mini_batch_size': 32, 'image_shape': '3,224,224', 'precision_dtype': 'float32'}\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:31 INFO 139925224236864] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'early_stopping': 'True', 'epochs': '10', 'image_shape': '3,224,224', 'learning_rate': '0.01', 'mini_batch_size': '128', 'num_classes': '17', 'num_layers': '18', 'num_training_samples': '28049', 'precision_dtype': 'float32', 'use_pretrained_model': '1'}\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:31 INFO 139925224236864] Final configuration: {'use_pretrained_model': '1', 'num_layers': '18', 'epochs': '10', 'learning_rate': '0.01', 'lr_scheduler_factor': 0.1, 'optimizer': 'sgd', 'momentum': 0, 'weight_decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'eps': 1e-08, 'gamma': 0.9, 'mini_batch_size': '128', 'image_shape': '3,224,224', 'precision_dtype': 'float32', 'early_stopping': 'True', 'num_classes': '17', 'num_training_samples': '28049'}\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:31 INFO 139925224236864] Searching for .lst files in /opt/ml/input/data/train_lst.\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:31 INFO 139925224236864] Creating record files for train.lst\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:51 INFO 139925224236864] Done creating record files...\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:51 INFO 139925224236864] Searching for .lst files in /opt/ml/input/data/validation_lst.\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:51 INFO 139925224236864] Creating record files for validation.lst\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] Done creating record files...\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] use_pretrained_model: 1\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] multi_label: 0\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] Using pretrained model for initializing weights and transfer learning.\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] ---- Parameters ----\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] num_layers: 18\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] data type: <class 'numpy.float32'>\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] epochs: 10\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] optimizer: sgd\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] momentum: 0.9\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] weight_decay: 0.0001\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] learning_rate: 0.01\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] num_training_samples: 28049\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] mini_batch_size: 128\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] image_shape: 3,224,224\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] num_classes: 17\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] augmentation_type: None\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] kv_store: device\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] Using early stopping for training\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] Early stopping minimum epochs: 10\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] Early stopping patience: 10\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] Early stopping tolerance: 0.01\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] --------------------\u001b[0m\n",
      "\u001b[34m[15:49:56] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_11.1.x.441.0/AL2_x86_64/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[34m[15:49:56] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_11.1.x.441.0/AL2_x86_64/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:49:56 INFO 139925224236864] Setting number of threads: 3\u001b[0m\n",
      "\u001b[34m[15:50:07] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_11.1.x.441.0/AL2_x86_64/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:50:16 INFO 139925224236864] Epoch[0] Batch [20]#011Speed: 240.781 samples/sec#011accuracy=0.635045\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:50:24 INFO 139925224236864] Epoch[0] Batch [40]#011Speed: 282.595 samples/sec#011accuracy=0.639863\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:50:31 INFO 139925224236864] Epoch[0] Batch [60]#011Speed: 299.696 samples/sec#011accuracy=0.601178\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:50:39 INFO 139925224236864] Epoch[0] Batch [80]#011Speed: 308.923 samples/sec#011accuracy=0.592303\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:50:47 INFO 139925224236864] Epoch[0] Batch [100]#011Speed: 314.539 samples/sec#011accuracy=0.592435\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:50:54 INFO 139925224236864] Epoch[0] Batch [120]#011Speed: 318.085 samples/sec#011accuracy=0.597237\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:51:02 INFO 139925224236864] Epoch[0] Batch [140]#011Speed: 320.655 samples/sec#011accuracy=0.609652\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:51:09 INFO 139925224236864] Epoch[0] Batch [160]#011Speed: 322.514 samples/sec#011accuracy=0.618498\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:51:17 INFO 139925224236864] Epoch[0] Batch [180]#011Speed: 323.918 samples/sec#011accuracy=0.626640\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:51:25 INFO 139925224236864] Epoch[0] Batch [200]#011Speed: 324.967 samples/sec#011accuracy=0.638060\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:51:32 INFO 139925224236864] Epoch[0] Train-accuracy=0.652540\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:51:32 INFO 139925224236864] Epoch[0] Time cost=85.677\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:51:39 INFO 139925224236864] Epoch[0] Validation-accuracy=0.760140\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:51:39 INFO 139925224236864] Storing the best model with validation accuracy: 0.760140\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:51:39 INFO 139925224236864] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:51:47 INFO 139925224236864] Epoch[1] Batch [20]#011Speed: 327.905 samples/sec#011accuracy=0.755580\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:51:54 INFO 139925224236864] Epoch[1] Batch [40]#011Speed: 330.450 samples/sec#011accuracy=0.744093\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:52:02 INFO 139925224236864] Epoch[1] Batch [60]#011Speed: 331.254 samples/sec#011accuracy=0.738601\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:52:10 INFO 139925224236864] Epoch[1] Batch [80]#011Speed: 331.650 samples/sec#011accuracy=0.739969\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:52:17 INFO 139925224236864] Epoch[1] Batch [100]#011Speed: 331.985 samples/sec#011accuracy=0.745127\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:52:25 INFO 139925224236864] Epoch[1] Batch [120]#011Speed: 332.065 samples/sec#011accuracy=0.745674\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:52:33 INFO 139925224236864] Epoch[1] Batch [140]#011Speed: 332.175 samples/sec#011accuracy=0.755098\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:52:40 INFO 139925224236864] Epoch[1] Batch [160]#011Speed: 332.284 samples/sec#011accuracy=0.760045\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:52:48 INFO 139925224236864] Epoch[1] Batch [180]#011Speed: 332.378 samples/sec#011accuracy=0.766100\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:52:56 INFO 139925224236864] Epoch[1] Batch [200]#011Speed: 332.439 samples/sec#011accuracy=0.772660\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:53:03 INFO 139925224236864] Epoch[1] Train-accuracy=0.781179\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:53:03 INFO 139925224236864] Epoch[1] Time cost=83.930\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:53:09 INFO 139925224236864] Epoch[1] Validation-accuracy=0.783967\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:53:09 INFO 139925224236864] Storing the best model with validation accuracy: 0.783967\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:53:09 INFO 139925224236864] Saved checkpoint to \"/opt/ml/model/image-classification-0002.params\"\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:53:17 INFO 139925224236864] Epoch[2] Batch [20]#011Speed: 327.091 samples/sec#011accuracy=0.859003\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:53:25 INFO 139925224236864] Epoch[2] Batch [40]#011Speed: 329.812 samples/sec#011accuracy=0.824505\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:53:33 INFO 139925224236864] Epoch[2] Batch [60]#011Speed: 330.707 samples/sec#011accuracy=0.815574\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:53:40 INFO 139925224236864] Epoch[2] Batch [80]#011Speed: 331.303 samples/sec#011accuracy=0.821181\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:53:48 INFO 139925224236864] Epoch[2] Batch [100]#011Speed: 331.626 samples/sec#011accuracy=0.827429\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:53:56 INFO 139925224236864] Epoch[2] Batch [120]#011Speed: 331.824 samples/sec#011accuracy=0.832645\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:54:03 INFO 139925224236864] Epoch[2] Batch [140]#011Speed: 331.920 samples/sec#011accuracy=0.841312\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:54:11 INFO 139925224236864] Epoch[2] Batch [160]#011Speed: 332.056 samples/sec#011accuracy=0.843168\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:54:19 INFO 139925224236864] Epoch[2] Batch [180]#011Speed: 332.160 samples/sec#011accuracy=0.845563\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:54:26 INFO 139925224236864] Epoch[2] Batch [200]#011Speed: 332.226 samples/sec#011accuracy=0.849658\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:54:33 INFO 139925224236864] Epoch[2] Train-accuracy=0.855843\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:54:33 INFO 139925224236864] Epoch[2] Time cost=83.987\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:54:40 INFO 139925224236864] Epoch[2] Validation-accuracy=0.835768\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:54:40 INFO 139925224236864] Storing the best model with validation accuracy: 0.835768\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:54:40 INFO 139925224236864] Saved checkpoint to \"/opt/ml/model/image-classification-0003.params\"\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:54:48 INFO 139925224236864] Epoch[3] Batch [20]#011Speed: 326.235 samples/sec#011accuracy=0.885417\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:54:55 INFO 139925224236864] Epoch[3] Batch [40]#011Speed: 329.569 samples/sec#011accuracy=0.848323\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:55:03 INFO 139925224236864] Epoch[3] Batch [60]#011Speed: 330.526 samples/sec#011accuracy=0.842725\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:55:11 INFO 139925224236864] Epoch[3] Batch [80]#011Speed: 331.065 samples/sec#011accuracy=0.850791\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:55:19 INFO 139925224236864] Epoch[3] Batch [100]#011Speed: 331.441 samples/sec#011accuracy=0.859066\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:55:26 INFO 139925224236864] Epoch[3] Batch [120]#011Speed: 331.676 samples/sec#011accuracy=0.865121\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:55:34 INFO 139925224236864] Epoch[3] Batch [140]#011Speed: 331.830 samples/sec#011accuracy=0.873116\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:55:42 INFO 139925224236864] Epoch[3] Batch [160]#011Speed: 331.938 samples/sec#011accuracy=0.878251\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:55:49 INFO 139925224236864] Epoch[3] Batch [180]#011Speed: 332.023 samples/sec#011accuracy=0.882424\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:55:57 INFO 139925224236864] Epoch[3] Batch [200]#011Speed: 332.120 samples/sec#011accuracy=0.887088\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:56:04 INFO 139925224236864] Epoch[3] Train-accuracy=0.891945\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:56:04 INFO 139925224236864] Epoch[3] Time cost=84.004\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:56:10 INFO 139925224236864] Epoch[3] Validation-accuracy=0.849185\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:56:10 INFO 139925224236864] Storing the best model with validation accuracy: 0.849185\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:56:10 INFO 139925224236864] Saved checkpoint to \"/opt/ml/model/image-classification-0004.params\"\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:56:18 INFO 139925224236864] Epoch[4] Batch [20]#011Speed: 326.839 samples/sec#011accuracy=0.925595\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:56:26 INFO 139925224236864] Epoch[4] Batch [40]#011Speed: 330.021 samples/sec#011accuracy=0.889482\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:56:34 INFO 139925224236864] Epoch[4] Batch [60]#011Speed: 330.729 samples/sec#011accuracy=0.889344\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:56:41 INFO 139925224236864] Epoch[4] Batch [80]#011Speed: 331.267 samples/sec#011accuracy=0.893422\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:56:49 INFO 139925224236864] Epoch[4] Batch [100]#011Speed: 331.504 samples/sec#011accuracy=0.900526\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:56:57 INFO 139925224236864] Epoch[4] Batch [120]#011Speed: 331.688 samples/sec#011accuracy=0.904765\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:57:04 INFO 139925224236864] Epoch[4] Batch [140]#011Speed: 331.881 samples/sec#011accuracy=0.910350\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:57:12 INFO 139925224236864] Epoch[4] Batch [160]#011Speed: 332.022 samples/sec#011accuracy=0.914062\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:57:20 INFO 139925224236864] Epoch[4] Batch [180]#011Speed: 332.129 samples/sec#011accuracy=0.917429\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:57:28 INFO 139925224236864] Epoch[4] Batch [200]#011Speed: 332.200 samples/sec#011accuracy=0.921214\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:57:34 INFO 139925224236864] Epoch[4] Train-accuracy=0.925050\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:57:34 INFO 139925224236864] Epoch[4] Time cost=83.982\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:57:41 INFO 139925224236864] Epoch[4] Validation-accuracy=0.845448\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:57:49 INFO 139925224236864] Epoch[5] Batch [20]#011Speed: 326.602 samples/sec#011accuracy=0.962426\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:57:57 INFO 139925224236864] Epoch[5] Batch [40]#011Speed: 329.569 samples/sec#011accuracy=0.919207\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:58:04 INFO 139925224236864] Epoch[5] Batch [60]#011Speed: 330.619 samples/sec#011accuracy=0.910476\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:58:12 INFO 139925224236864] Epoch[5] Batch [80]#011Speed: 331.189 samples/sec#011accuracy=0.914545\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:58:20 INFO 139925224236864] Epoch[5] Batch [100]#011Speed: 331.500 samples/sec#011accuracy=0.922107\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:58:27 INFO 139925224236864] Epoch[5] Batch [120]#011Speed: 331.715 samples/sec#011accuracy=0.926588\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:58:35 INFO 139925224236864] Epoch[5] Batch [140]#011Speed: 331.893 samples/sec#011accuracy=0.930463\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:58:43 INFO 139925224236864] Epoch[5] Batch [160]#011Speed: 332.028 samples/sec#011accuracy=0.933861\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:58:50 INFO 139925224236864] Epoch[5] Batch [180]#011Speed: 332.118 samples/sec#011accuracy=0.937543\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:58:58 INFO 139925224236864] Epoch[5] Batch [200]#011Speed: 332.157 samples/sec#011accuracy=0.940299\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:59:05 INFO 139925224236864] Epoch[5] Train-accuracy=0.942815\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:59:05 INFO 139925224236864] Epoch[5] Time cost=84.002\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:59:11 INFO 139925224236864] Epoch[5] Validation-accuracy=0.807015\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:59:19 INFO 139925224236864] Epoch[6] Batch [20]#011Speed: 326.999 samples/sec#011accuracy=0.968750\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:59:27 INFO 139925224236864] Epoch[6] Batch [40]#011Speed: 330.051 samples/sec#011accuracy=0.938453\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:59:35 INFO 139925224236864] Epoch[6] Batch [60]#011Speed: 331.039 samples/sec#011accuracy=0.933658\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:59:42 INFO 139925224236864] Epoch[6] Batch [80]#011Speed: 331.547 samples/sec#011accuracy=0.937018\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:59:50 INFO 139925224236864] Epoch[6] Batch [100]#011Speed: 331.812 samples/sec#011accuracy=0.942528\u001b[0m\n",
      "\u001b[34m[06/19/2025 15:59:58 INFO 139925224236864] Epoch[6] Batch [120]#011Speed: 332.009 samples/sec#011accuracy=0.946539\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:00:05 INFO 139925224236864] Epoch[6] Batch [140]#011Speed: 331.964 samples/sec#011accuracy=0.949302\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:00:13 INFO 139925224236864] Epoch[6] Batch [160]#011Speed: 331.913 samples/sec#011accuracy=0.952300\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:00:21 INFO 139925224236864] Epoch[6] Batch [180]#011Speed: 332.020 samples/sec#011accuracy=0.955067\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:00:29 INFO 139925224236864] Epoch[6] Batch [200]#011Speed: 332.117 samples/sec#011accuracy=0.956623\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:00:35 INFO 139925224236864] Epoch[6] Train-accuracy=0.958619\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:00:35 INFO 139925224236864] Epoch[6] Time cost=84.005\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:00:42 INFO 139925224236864] Epoch[6] Validation-accuracy=0.879586\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:00:42 INFO 139925224236864] Storing the best model with validation accuracy: 0.879586\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:00:42 INFO 139925224236864] Saved checkpoint to \"/opt/ml/model/image-classification-0007.params\"\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:00:50 INFO 139925224236864] Epoch[7] Batch [20]#011Speed: 326.630 samples/sec#011accuracy=0.973214\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:00:58 INFO 139925224236864] Epoch[7] Batch [40]#011Speed: 329.724 samples/sec#011accuracy=0.966082\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:01:05 INFO 139925224236864] Epoch[7] Batch [60]#011Speed: 330.795 samples/sec#011accuracy=0.960938\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:01:13 INFO 139925224236864] Epoch[7] Batch [80]#011Speed: 331.315 samples/sec#011accuracy=0.962384\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:01:21 INFO 139925224236864] Epoch[7] Batch [100]#011Speed: 331.542 samples/sec#011accuracy=0.964418\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:01:28 INFO 139925224236864] Epoch[7] Batch [120]#011Speed: 331.741 samples/sec#011accuracy=0.967071\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:01:36 INFO 139925224236864] Epoch[7] Batch [140]#011Speed: 331.916 samples/sec#011accuracy=0.967697\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:01:44 INFO 139925224236864] Epoch[7] Batch [160]#011Speed: 332.042 samples/sec#011accuracy=0.969041\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:01:51 INFO 139925224236864] Epoch[7] Batch [180]#011Speed: 332.154 samples/sec#011accuracy=0.970951\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:01:59 INFO 139925224236864] Epoch[7] Batch [200]#011Speed: 332.219 samples/sec#011accuracy=0.972093\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:02:06 INFO 139925224236864] Epoch[7] Train-accuracy=0.973566\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:02:06 INFO 139925224236864] Epoch[7] Time cost=83.978\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:02:12 INFO 139925224236864] Epoch[7] Validation-accuracy=0.879076\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:02:20 INFO 139925224236864] Epoch[8] Batch [20]#011Speed: 326.891 samples/sec#011accuracy=0.986979\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:02:28 INFO 139925224236864] Epoch[8] Batch [40]#011Speed: 329.687 samples/sec#011accuracy=0.979611\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:02:36 INFO 139925224236864] Epoch[8] Batch [60]#011Speed: 330.747 samples/sec#011accuracy=0.976819\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:02:43 INFO 139925224236864] Epoch[8] Batch [80]#011Speed: 331.296 samples/sec#011accuracy=0.977431\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:02:51 INFO 139925224236864] Epoch[8] Batch [100]#011Speed: 331.588 samples/sec#011accuracy=0.977568\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:02:59 INFO 139925224236864] Epoch[8] Batch [120]#011Speed: 331.819 samples/sec#011accuracy=0.978758\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:03:06 INFO 139925224236864] Epoch[8] Batch [140]#011Speed: 331.991 samples/sec#011accuracy=0.979444\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:03:14 INFO 139925224236864] Epoch[8] Batch [160]#011Speed: 332.109 samples/sec#011accuracy=0.979814\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:03:22 INFO 139925224236864] Epoch[8] Batch [180]#011Speed: 332.202 samples/sec#011accuracy=0.980836\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:03:30 INFO 139925224236864] Epoch[8] Batch [200]#011Speed: 332.264 samples/sec#011accuracy=0.981382\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:03:36 INFO 139925224236864] Epoch[8] Train-accuracy=0.981878\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:03:36 INFO 139925224236864] Epoch[8] Time cost=83.977\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:03:43 INFO 139925224236864] Epoch[8] Validation-accuracy=0.886549\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:03:43 INFO 139925224236864] Storing the best model with validation accuracy: 0.886549\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:03:43 INFO 139925224236864] Saved checkpoint to \"/opt/ml/model/image-classification-0009.params\"\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:03:51 INFO 139925224236864] Epoch[9] Batch [20]#011Speed: 326.920 samples/sec#011accuracy=0.990699\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:03:58 INFO 139925224236864] Epoch[9] Batch [40]#011Speed: 329.877 samples/sec#011accuracy=0.985328\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:04:06 INFO 139925224236864] Epoch[9] Batch [60]#011Speed: 330.944 samples/sec#011accuracy=0.983735\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:04:14 INFO 139925224236864] Epoch[9] Batch [80]#011Speed: 331.398 samples/sec#011accuracy=0.984471\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:04:22 INFO 139925224236864] Epoch[9] Batch [100]#011Speed: 331.717 samples/sec#011accuracy=0.984839\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:04:29 INFO 139925224236864] Epoch[9] Batch [120]#011Speed: 331.935 samples/sec#011accuracy=0.985795\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:04:37 INFO 139925224236864] Epoch[9] Batch [140]#011Speed: 332.051 samples/sec#011accuracy=0.985926\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:04:45 INFO 139925224236864] Epoch[9] Batch [160]#011Speed: 332.123 samples/sec#011accuracy=0.986267\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:04:52 INFO 139925224236864] Epoch[9] Batch [180]#011Speed: 332.186 samples/sec#011accuracy=0.986835\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:05:00 INFO 139925224236864] Epoch[9] Batch [200]#011Speed: 332.254 samples/sec#011accuracy=0.987446\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:05:07 INFO 139925224236864] Epoch[9] Train-accuracy=0.988049\u001b[0m\n",
      "\u001b[34m[06/19/2025 16:05:07 INFO 139925224236864] Epoch[9] Time cost=83.994\u001b[0m\n",
      "\n",
      "2025-06-19 16:05:20 Uploading - Uploading generated training model\u001b[34m[06/19/2025 16:05:13 INFO 139925224236864] Epoch[9] Validation-accuracy=0.885870\u001b[0m\n",
      "\n",
      "2025-06-19 16:05:33 Completed - Training job completed\n",
      "Training seconds: 1165\n",
      "Billable seconds: 1165\n"
     ]
    }
   ],
   "source": [
    "ic_estimator.fit(inputs=input_data, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa7d74-8dd0-498c-a434-01ae902085c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
